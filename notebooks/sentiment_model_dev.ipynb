{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e26b1e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "import re\n",
    "import string\n",
    "import mlflow\n",
    "\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "943d06f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and saved to data/raw_feedback.csv\n",
      "                                                text sentiment\n",
      "0         This product is amazing! Highly recommend.  positive\n",
      "1                Very disappointed with the quality.  negative\n",
      "2                         Works okay, but not great.   neutral\n",
      "3  Excellent customer service, resolved my issue ...  positive\n",
      "4           The app is buggy and crashes frequently.  negative\n"
     ]
    }
   ],
   "source": [
    "# Simulate loading data\n",
    "data = {\n",
    "    'text': [\n",
    "        \"This product is amazing! Highly recommend.\",\n",
    "        \"Very disappointed with the quality.\",\n",
    "        \"Works okay, but not great.\",\n",
    "        \"Excellent customer service, resolved my issue quickly.\",\n",
    "        \"The app is buggy and crashes frequently.\",\n",
    "        \"I love the new features!\",\n",
    "        \"It's terrible, don't buy it.\",\n",
    "        \"Average experience, nothing special.\",\n",
    "        \"Best purchase I've made this year!\",\n",
    "        \"Waste of money and time.\"\n",
    "    ],\n",
    "    'sentiment': ['positive', 'negative', 'neutral', 'positive', 'negative', 'positive', 'negative', 'neutral', 'positive', 'negative']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the raw data (simulate data source versioning with DVC later)\n",
    "# Create a 'data' directory if it doesn't exist\n",
    "import os\n",
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')\n",
    "df.to_csv('data/raw_feedback.csv', index=False)\n",
    "\n",
    "print(\"Data loaded and saved to data/raw_feedback.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38ea6cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessed Data Sample:\n",
      "                                                text  \\\n",
      "0         This product is amazing! Highly recommend.   \n",
      "1                Very disappointed with the quality.   \n",
      "2                         Works okay, but not great.   \n",
      "3  Excellent customer service, resolved my issue ...   \n",
      "4           The app is buggy and crashes frequently.   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0           this product is amazing highly recommend  \n",
      "1                 very disappointed with the quality  \n",
      "2                           works okay but not great  \n",
      "3  excellent customer service resolved my issue q...  \n",
      "4            the app is buggy and crashes frequently  \n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"Basic text cleaning: lowercase, remove punctuation, remove extra whitespace.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\" # Handle potential non-string data gracefully\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing to the dataframe (for EDA/training prep)\n",
    "df['cleaned_text'] = df['text'].apply(preprocess_text)\n",
    "print(\"\\nPreprocessed Data Sample:\")\n",
    "print(df[['text', 'cleaned_text']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b13d47bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set size: 7\n",
      "Test set size: 3\n"
     ]
    }
   ],
   "source": [
    "X = df['cleaned_text']\n",
    "y = df['sentiment']\n",
    "\n",
    "# Split data for training and evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"\\nTraining set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f3dd6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/13 17:04:56 INFO mlflow.tracking.fluent: Experiment with name 'Sentiment Analysis Dev' does not exist. Creating a new experiment.\n",
      "/Users/shivaram.sivagurunathan/Documents/vscode project/MLFlow/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/shivaram.sivagurunathan/Documents/vscode project/MLFlow/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/shivaram.sivagurunathan/Documents/vscode project/MLFlow/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/shivaram.sivagurunathan/Documents/vscode project/MLFlow/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/shivaram.sivagurunathan/Documents/vscode project/MLFlow/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/shivaram.sivagurunathan/Documents/vscode project/MLFlow/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model training complete.\n",
      "\n",
      "Test Set Accuracy: 0.3333\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      1.00      0.50         1\n",
      "     neutral       0.00      0.00      0.00         1\n",
      "    positive       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.33         3\n",
      "   macro avg       0.11      0.33      0.17         3\n",
      "weighted avg       0.11      0.33      0.17         3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/04/13 17:04:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLflow Run ID: acfc159c19df49ea95b18e1b49af50d0\n",
      "Model, parameters, and metrics logged to MLflow.\n"
     ]
    }
   ],
   "source": [
    "# MLflow Tracking Setup\n",
    "mlflow.set_experiment(\"Sentiment Analysis Dev\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"LogisticRegression_TFIDF\") as run:\n",
    "    # Define model pipeline: TF-IDF Vectorizer + Logistic Regression\n",
    "    model_pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "        ('clf', LogisticRegression(solver='liblinear', random_state=42)) # liblinear is good for small datasets\n",
    "    ])\n",
    "\n",
    "    # Train the model\n",
    "    model_pipeline.fit(X_train, y_train)\n",
    "    print(\"\\nModel training complete.\")\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model_pipeline.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\nTest Set Accuracy: {accuracy:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Log parameters, metrics, and the model with MLflow\n",
    "    mlflow.log_param(\"model_type\", \"LogisticRegression\")\n",
    "    mlflow.log_param(\"vectorizer\", \"TfidfVectorizer\")\n",
    "    mlflow.log_param(\"random_state\", 42)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    # Log the classification report as a text file artifact\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    with open(\"classification_report.txt\", \"w\") as f:\n",
    "        f.write(report)\n",
    "    mlflow.log_artifact(\"classification_report.txt\")\n",
    "    os.remove(\"classification_report.txt\") # Clean up the local file\n",
    "\n",
    "    # Log the scikit-learn pipeline model\n",
    "    mlflow.sklearn.log_model(model_pipeline, \"sentiment-model\")\n",
    "\n",
    "    print(f\"\\nMLflow Run ID: {run.info.run_id}\")\n",
    "    print(\"Model, parameters, and metrics logged to MLflow.\")\n",
    "\n",
    "# Keep track of the best run ID (in this simple case, it's the only run)\n",
    "best_run_id = run.info.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bb24ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model pipeline saved locally to models/sentiment_pipeline.joblib\n",
      "Model loaded successfully for verification.\n",
      "Prediction for 'This is a fantastic service!': positive\n"
     ]
    }
   ],
   "source": [
    "# Create a 'models' directory if it doesn't exist\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "\n",
    "# Save the trained pipeline locally using joblib\n",
    "model_filename = 'models/sentiment_pipeline.joblib'\n",
    "joblib.dump(model_pipeline, model_filename)\n",
    "\n",
    "print(f\"\\nModel pipeline saved locally to {model_filename}\")\n",
    "\n",
    "# (Optional but good practice) Load the model back to verify\n",
    "loaded_pipeline = joblib.load(model_filename)\n",
    "print(\"Model loaded successfully for verification.\")\n",
    "# Test with a sample prediction\n",
    "sample_text = \"This is a fantastic service!\"\n",
    "cleaned_sample = preprocess_text(sample_text)\n",
    "prediction = loaded_pipeline.predict([cleaned_sample])\n",
    "print(f\"Prediction for '{sample_text}': {prediction[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
